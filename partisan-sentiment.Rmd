---
title: using political tweets to build a partisan sentiment classifier
output:
  html_document:
    toc: true
    toc_float: true
---

## setup

```{r}
library(tidyverse)
library(tidytext)
library(magrittr)
library(jsonlite)
library(lubridate)
library(here)
library(scales)
library(ggrepel)
library(mongolite)

knitr::opts_chunk$set(
  engine.path = list(
  sh = "C:/Program Files/Git/bin/sh.exe",
  bash = "C:/Program Files/Git/bin/bash.exe"
  ),
  cache = TRUE
  )
```

## fetch data

```{r, eval=FALSE}

dl <- c(
  tweets =  "https://files.pushshift.io/misc/political_tweets.ndjson.xz"
  voteview = "https://voteview.com/static/db/current.zip"
  )

walk2(dl, names(dl), 
  ~download.file(
    url = .x,
    destfile = here("raw", basename(.y))
    )
  )

unzip(here("raw", "current.zip"), overwrite = TRUE, exdir = here("raw", "voteview"))

```


## twitter data

Tweets are the history of tweets for any member of the 115th Congress, plus other contemporaneous active political figures


```{bash, eval=FALSE}

# uncompress with xz

unxz political_tweets.ndjson.xz

# pull the frst and last

head -n 1 raw/political_tweets.ndjson > raw/first.ndjson
tail -n 1 raw/political_tweets.ndjson > raw/last.ndjson

```

### get an idea for what twitter data looks like

```{r}
c("raw/first.ndjson", "raw/last.ndjson") %>%
  map(read_json) %>%
  walk(str)
```

### use `jq` to grab the full tweet text

```{bash, eval=FALSE}

cat raw/political_tweets.ndjson | jq -c '{ handle : .user.screen_name, tweeted_at : .created_at, full_text : .full_text }' > raw/tweet_text.ndjson
```


```{r}
tweets <- stream_in(file("raw/tweet_text.ndjson"))
remove_regex <- "&amp;|&lt;|&gt;"

x <- tweets %>%
  mutate(
    time_of_tweet = parse_date_time(tweeted_at, "abdHMszY"),
    tweet_month = month(time_of_tweet),
    tweet_year = year(time_of_tweet)
  ) %>%
  filter(!str_detect(full_text, "^RT")) %>%
  mutate(full_text = str_remove_all(full_text, remove_regex)) %>%
  unnest_tokens(word, full_text, token = "tweets") %>%
  anti_join(stop_words)
```

## voteview data

DW nominate scores are provided in batch as mongoDB BSON files, so start a local mongo instance to view members collection

```{bash, eval=FALSE}
docker run -d --rm -p 27017:27017 mongo
```

### load data into mongo and extract info

```{r}
m <- mongo("members", "voteview", url = "mongodb://localhost:27017")
m$import(file(here::here("raw", "voteview", "dump", "voteview", "voteview_members.bson")), bson = TRUE)

members_115 <- m$find(
  '{"congress":115}',
  fields = '{"twitter" : true, "chamber": true, "party_code" : true, "nominate.dim1": true, "bioname" : true, "_id": false }'
)
scores <- members_115$nominate
members_115$nominate <- NULL
members_115 %<>% bind_cols(members_115, scores) %>% as_tibble()

members <-
  members_115 %>%
  mutate(
    party_code = as.double(party_code),
    # "independents"
    party_code = case_when(
      twitter == "SenAngusKing" ~ 100,
      twitter == "SenSanders" ~ 100,
      TRUE ~ party_code
    ),
    party = case_when(
      party_code == 100 ~ "D",
      party_code == 200 ~ "R"
    )
  ) %>%
  select(party, left_right = dim1, handle = twitter, bioname, chamber)
```

Combine tweets with voteview info

```{r}
tidied <- inner_join(x, members, by = "handle")
```

## plots

### relatve frequency

Words used by both partisans, by relative frequency

```{r}
freq <- tidied %>%
  group_by(party) %>%
  count(word, sort = TRUE) %>%
  left_join(tidied %>% group_by(party) %>% summarise(total = n())) %>%
  mutate(freq = n/total) %>%
  select(party, word, freq) %>%
  spread(party, freq)
```

### plot 1

```{r, fig.width=10,fig.height=11}

freq %>%
  drop_na() %>%
ggplot(., aes(D, R)) +
  geom_jitter(alpha = 0.1, size = 2.5, width = 0.25, height = 0.25) +
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
  scale_x_log10(labels = percent_format()) +
  scale_y_log10(labels = percent_format()) +
  geom_abline(color = "red") +
  labs(
    title = "Building a partisan vocabulary:",
    subtitle = "Relative frequencies of words mentioned by members of Congress on Twitter"
  )
```

### salient words by chamber and party

```{r}
tfidf <-
  tidied %>%
  mutate(chamber_party = str_c(party,"-", chamber)) %>%
  group_by(chamber_party, word) %>%
  summarise(
    n = n(),
    avg_partisan_affect = mean(left_right, na.rm = TRUE)
  ) %>%
  ungroup() %>%
  bind_tf_idf(word, chamber_party, n)

top_tfidf <- tfidf %>%
  group_by(chamber_party) %>%
  top_n(100, tf_idf)
```


### plot 2

```{r, fig.width=10,fig.height=11}

top_tfidf %>%
  drop_na(word) %>%
  filter(chamber_party != "R-President") %>%
  ggplot(., aes(avg_partisan_affect, tf_idf, label = word)) +
  geom_text_repel(
    segment.alpha = 0,
    aes(colour=avg_partisan_affect)
    ) +
  facet_wrap("chamber_party", nrow = 2) +
  scale_colour_distiller(
    palette = "RdBu",
    guide = guide_colourbar(direction = "horizontal",
    title.position ="top")
    )+
  labs(
    title = "Building a partisan vocabulary:",
    subtitle = "What are the most salient words tweeted by Democrats and Republicans?",
    x = "Average DW Nominate score (by word)",
    y = "TF / IDF"
  ) +
  theme_minimal()

```
